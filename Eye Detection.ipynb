{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #ROI Region Of Interestt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the Haar cascade files for face and eye\n",
    "face_cascade = cv2.CascadeClassifier('haar_cascade_files/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haar_cascade_files/haarcascade_eye.xml')\n",
    "\n",
    "# Check if the face cascade file has been loaded correctly\n",
    "if face_cascade.empty():\n",
    "    raise IOError('Unable to load the face cascade classifier xml file')\n",
    "\n",
    "# Check if the eye cascade file has been loaded correctly\n",
    "if eye_cascade.empty():\n",
    "    raise IOError('Unable to load the eye cascade classifier xml file')\n",
    "\n",
    "# Initialize the video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the scaling factor\n",
    "ds_factor = 0.5\n",
    "\n",
    "# Iterate until the user hits the 'Esc' key\n",
    "while True:\n",
    "    # Capture the current frame\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    # Resize the frame\n",
    "    frame = cv2.resize(frame, None, fx=ds_factor, fy=ds_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Run the face detector on the grayscale image\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    \n",
    "    # For each face that's detected, run the eye detector\n",
    "    #xy,wh, son las coordenadas de la cara, \n",
    "    #usando la imagen completa en gris, de ahi usas las coordenadas [gray]\n",
    "    #Asi mismo con la de color [frame]\n",
    "    #dentro de esta cara, se corre el cascade de ojos, y se pinta circulos verdes\n",
    "    for (x,y,w,h) in faces:\n",
    "        \n",
    "        # Extract the grayscale face ROI\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Extract the color face ROI\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Run the eye detector on the grayscale ROI\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        # Draw circles around the eyes\n",
    "        for (x_eye,y_eye,w_eye,h_eye) in eyes:\n",
    "            center = (int(x_eye + 0.5*w_eye), int(y_eye + 0.5*h_eye))\n",
    "            radius = int(0.3 * (w_eye + h_eye))\n",
    "            color = (0, 255, 0)\n",
    "            thickness = 3\n",
    "            cv2.circle(roi_color, center, radius, color, thickness)\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow('Eye Detector', frame)\n",
    "\n",
    "    # Check if the user hit the 'Esc' key\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Close all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sumary\n",
    "SummaryIn this chapter, we learnt about object detection and tracking. We understood how to install OpenCV with Python support on various operating systems. We learnt about frame differencing and used it to detect the moving parts in a video. We discussed how to track human skin using color spaces. We talked about background subtraction and how it can be used to track objects in static scenes. We built an interactive object tracker using the CAMShift algorithm.We learnt how to build an optical flow based tracker. We discussed face detection techniques and understood the concepts of Haar cascades and integral images. We used this technique to build an eye detector and tracker. In the next chapter, we will discuss artificial neural networks and use those techniques to build an optical character recognition engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
