{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable. Bayes’ theorem states the following relationship, given class variable  and dependent feature vector \n",
    " through \n",
    ", :\n",
    "\n",
    " \n",
    "Using the naive conditional independence assumption that\n",
    "\n",
    "for all , this relationship is simplified to\n",
    "\n",
    " \n",
    "Since \n",
    " is constant given the input, we can use the following classification rule:\n",
    "\n",
    " \n",
    " \n",
    " \n",
    "  \n",
    "and we can use Maximum A Posteriori (MAP) estimation to estimate  and \n",
    "; the former is then the relative frequency of class  in the training set.\n",
    "\n",
    "The different naive Bayes classifiers differ mainly by the assumptions they make regarding the distribution of \n",
    ".\n",
    "\n",
    "In spite of their apparently over-simplified assumptions, naive Bayes classifiers have worked quite well in many real-world situations, famously document classification and spam filtering. They require a small amount of training data to estimate the necessary parameters. (For theoretical reasons why naive Bayes works well, and on which types of data it does, see the references below.)\n",
    "\n",
    "Naive Bayes learners and classifiers can be extremely fast compared to more sophisticated methods. The decoupling of the class conditional feature distributions means that each distribution can be independently estimated as a one dimensional distribution. This in turn helps to alleviate problems stemming from the curse of dimensionality.\n",
    "\n",
    "On the flip side, although naive Bayes is known as a decent classifier, it is known to be a bad estimator, so the probability outputs from predict_proba are not to be taken too seriously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GaussianNB implements the Gaussian Naive Bayes algorithm for classification. The likelihood of the features is assumed to be Gaussian:\n",
    "\n",
    " \n",
    " \n",
    "The parameters \n",
    " and \n",
    " are estimated using maximum likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 75 points: 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "X, y = load_iris(return_X_y =True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.5, random_state=0)\n",
    "gnb = GaussianNB()\n",
    "y_pred= gnb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points: %d\"\n",
    "     % (X_test.shape[0], (y_test != y_pred).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and counting\n",
    "Create a bag of words, counting all the words, ignoring case. Using a regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prettytable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-badc3fc49b63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mprettytable\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrettyTable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_punctuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prettytable'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string \n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def remove_punctuation(s):\n",
    "    table = string.maketrans(\"\",\"\")\n",
    "    return s.translate(table, string.punctuation)\n",
    "\n",
    "def tokenize(text):\n",
    "    text = remove_punctuation(text)\n",
    "    text = text.lower()\n",
    "    return re.split(\"\\W+\", text)\n",
    "\n",
    "def count_words(words):\n",
    "    wc={}\n",
    "    for word in words:\n",
    "        wc[word]=wc.get(word,0.0)+1.0\n",
    "    return wc\n",
    "\n",
    "s = \"Hello my name is Ivan. My favorite food is sushi\"\n",
    "count_words(tokenize(s))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting our probabilities\n",
    "So now that we can count words, lets get cooking. The code below is going to do the following:\n",
    " * open each document\n",
    " * label it as aeither \"crypto\" or \"dino\" and keep track of how many of each label there are (priors)\n",
    " * count the words for the document\n",
    " * add those counts to the vocab, or a corpus level word count\n",
    " * add those counts to the word_count, for a category level word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-047e694880bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mpriors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "from sh import find\n",
    "\n",
    "#setup some structures to store our data\n",
    "vocab={}\n",
    "word_count = {\n",
    "    \"crypto\":{},\n",
    "    \"dino\":{}\n",
    "}\n",
    "priors ={\n",
    "    'crypto':0.,\n",
    "    'dino':0.\n",
    "}\n",
    "docs=[]\n",
    "for f in find(\"nb_files/sample-data\"):\n",
    "    f=f.strip()\n",
    "    if f.endswith(\".txt\")==False:\n",
    "        #skip non .txt files\n",
    "        continue\n",
    "    elif \"cryptid\" in f:\n",
    "        category =\"cryto\"\n",
    "    else:\n",
    "        category = \"dino\"\n",
    "    docs.append((category,f))\n",
    "    #ok time to start counting stuff\n",
    "    priors[category] += 1\n",
    "    text = open(f).read()\n",
    "    words = tokenize(text)\n",
    "    counts = count_words(words)\n",
    "    for word, count in counts.items():\n",
    "        #if we havent seen a word yet, lets add it to our dictionaries with a count of 0\n",
    "        if word not in vocab:\n",
    "            vocab[word]=0.0 #use 0.0 here so python does \"correct\" math\n",
    "        if word not in word_counts[category]:\n",
    "            word_counts[category][word]=0.0\n",
    "        vocab[word] += count\n",
    "        word_counts[category][word] += count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Classifying a new page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d8f7335ea880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nb_files/examples/Yeti.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_doc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "new_doc = open(\"nb_files/examples/Yeti.txt\").read()\n",
    "words= tokenize(new_doc)\n",
    "counts = count_words(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we've got our counts. Now we'll calculate P(word|category) for each word and multiply each of these conditional probabilities together to calculate the P(category|set of words). To prevent computational errors, we're going to perform the operations in logspace. All this means is we're going to use the log(probability) so we require fewer decimal places. More on the mystical properties of logs here and here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2d8dd3342f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlog_prob_dino\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#Skip words that we havent seen before, or words less than 3 letters long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count_items' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "prior_dino= (priors['dino'] / sum(priors.values()))\n",
    "prior_crypto= (priors['crypto'] / sum(priors.values()))\n",
    "\n",
    "log_prob_crypto =0.0\n",
    "log_prob_dino =0.0\n",
    "\n",
    "for w, cnt in count_items():\n",
    "    #Skip words that we havent seen before, or words less than 3 letters long\n",
    "    if not w in vocab or len(w) <=3:\n",
    "        continue\n",
    "    #Calculate the probability that the word occurs at all\n",
    "    p_word = vocab[w] / sum(vocab.values())\n",
    "    #for both categories, calculate P(word[category]), or the probability a\n",
    "    #  word will appear, given that we know that the document is <category>\n",
    "    p_w_given_dino = word_counts[\"dino\"].get(w,0.0) / sum(word_counts[\"dino\"].values())\n",
    "    p_w_given_crypto = word_counts[\"crypto\"].get(w, 0.0) / sum(word_counts[\"crypto\"].values())\n",
    "    #add new probability to our running total\" log_prob_<category> if the probability\n",
    "    #is 0 (i.e the word never appears for the category ), then skip it\n",
    "    if p_w_given_dino> 0 :\n",
    "        log_prob_dino += math.log(cnt * p_w_given_dino / p_word)\n",
    "    if p_w_given_crypto > 0 :\n",
    "        log_prob_crypto += math.log(cnt * p_w_given_crypto / p_word)\n",
    "        \n",
    "    #Print out the results; we need to go from logspace back to \"regular\" space\n",
    "    # so we take the EXP of the log_prob \n",
    "    print(\"Score(dino):\", math.exp(log_prob_dino + math.log(prior_dino)))\n",
    "    print(\"Score (crypto):\",math.exp(log_prob_crypto + math.log(prior_crypto)))\n",
    "    #dino; 2601.766\n",
    "    #crypto: 25239.089"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're slightly bending the rules of Bayes' Theorem, the results are not actual probabilities, but rather are \"scores\". All you really need to know is which one is bigger. So our suspicions are confirmed, the \"Yeti.txt\" file is being classified overwhelmingly in favor of crypto (as we would hope)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another tutorial on the web\n",
    "https://www.youtube.com/watch?v=99MN-rl8jGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import urllib.request\n",
    "import sklearn\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#python 3\n",
    "#with urllib.request.urlopen(\"http://www.python.org\") as url:\n",
    "#    s = url.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.      0.64    0.64    0.      0.32    0.      0.      0.      0.\n",
      "   0.      0.      0.64    0.      0.      0.      0.32    0.      1.29\n",
      "   1.93    0.      0.96    0.      0.      0.      0.      0.      0.\n",
      "   0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "   0.      0.      0.      0.      0.      0.      0.      0.      0.\n",
      "   0.      0.      0.      0.      0.      0.      0.778   0.      0.\n",
      "   3.756  61.    278.      1.   ]\n"
     ]
    }
   ],
   "source": [
    "url =\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "raw_data= urllib.request.urlopen(url) #python 2.x urllib.urlopen(url) \n",
    "dataset=np.loadtxt(raw_data, delimiter=\",\")\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= dataset[:, 0:48]\n",
    "y = dataset[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.33, random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1.0, binarize=True, class_prior=None, fit_prior=True)\n",
      "0.8558262014483212\n"
     ]
    }
   ],
   "source": [
    "BernNB = BernoulliNB(binarize = True)\n",
    "BernNB.fit(X_train, y_train)\n",
    "print(BernNB)\n",
    "#label\n",
    "y_expect=y_test\n",
    "y_pred=BernNB.predict(X_test)\n",
    "print(accuracy_score(y_expect,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.8736010533245556\n"
     ]
    }
   ],
   "source": [
    "MultiNB = MultinomialNB()\n",
    "MultiNB.fit(X_train, y_train)\n",
    "print(MultiNB)\n",
    "\n",
    "y_pred=MultiNB.predict(X_test)\n",
    "print(accuracy_score(y_expect,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "0.8130348913759052\n"
     ]
    }
   ],
   "source": [
    "GausNB = GaussianNB()\n",
    "GausNB.fit(X_train, y_train)\n",
    "print(GausNB)\n",
    "\n",
    "y_pred=GausNB.predict(X_test)\n",
    "print(accuracy_score(y_expect,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### improved versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1.0, binarize=0.1, class_prior=None, fit_prior=True)\n",
      "0.8940092165898618\n"
     ]
    }
   ],
   "source": [
    "BernNB= BernoulliNB(binarize=0.1)\n",
    "BernNB.fit(X_test,y_test)\n",
    "print(BernNB)\n",
    "y_expect= y_test\n",
    "y_pred=BernNB.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_expect,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
