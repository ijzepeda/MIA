{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame differencing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simplest techniques to be used to identify moving parts on a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#comput the frame differences\n",
    "def frame_diff(prev_frame, cur_frame, next_frame):\n",
    "    #difference between the current frame and the next frame\n",
    "    diff_frames_1 = cv2.absdiff(next_frame, cur_frame)\n",
    "    #difference between the current freame and the previous frame\n",
    "    diff_frames_2 = cv2.absdiff(cur_frame, prev_frame)\n",
    "    #compute bitwise and between the two differences frames and return it\n",
    "    return cv2.bitwise_and(diff_frames_1, diff_frames_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to get the current frame from the webcam\n",
    "def get_frame(cap, scaling_factor):\n",
    "    #read the current frame from the video capture object\n",
    "    _, frame = cap.read()\n",
    "    #resize the image\n",
    "    frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "    #convert to grayscale\n",
    "    gray=cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    return gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the main function and initialize the video capture object\n",
    "if __name__=='__main__':\n",
    "    #define the video capture object\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    #define the scaling factor for the images\n",
    "    scaling_factor =0.5\n",
    "    #grab the current frame\n",
    "    prev_frame = get_frame(cap, scaling_factor)\n",
    "    #grab the next frame\n",
    "    cur_frame= get_frame(cap, scaling_factor)\n",
    "    #grab the frame adter that\n",
    "    next_frame = get_frame(cap, scaling_factor)\n",
    "      #keep reading the frames from the webcam\n",
    "      #until the user hits the ESC key\n",
    "    while True:\n",
    "        #Displau the frame difference\n",
    "        cv2.imshow(\"Object movement\", frame_diff(prev_frame, cur_frame, next_frame))\n",
    "        #Update the variables\n",
    "        prev_frame= cur_frame\n",
    "        cur_frame = next_frame\n",
    "        #grab the next frame\n",
    "        next_frame= get_frame(cap, scaling_factor)\n",
    "        #Check if the user hit the ESC key\n",
    "        key=cv2.waitKey(10)\n",
    "        if key==27:\n",
    "            break\n",
    "    #close all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking objects using colospaces\n",
    "to buikd a robust object tracker, we need to know what charactersitics of the object can be used to track it accurately, this is where color spaces become relevant.\n",
    "RGB is the most popular but doestn work well with object tracking, we use HSV (and it is similar to what we perceive as human eyes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
